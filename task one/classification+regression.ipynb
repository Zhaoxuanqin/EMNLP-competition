{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AnktrduOniFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba78268-c66d-4785-d896-47f25b36ca58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 59.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 67.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.4.0 multiprocess-0.70.13 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install datasets\n",
        "!pip install torchmetrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XypgnHCEnnXt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AdamW\n",
        "from collections import defaultdict\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HCm106FxnohQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import datasets\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from numpy import *\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbUCUJJQnp1j",
        "outputId": "c8731c1d-0212-4615-96bf-3188830cc335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/新建文件夹/ERAI Dataset_with_translation\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/新建文件夹/ERAI Dataset_with_translation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "ik9XajY6yGqJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_unsupervised = pd.read_json('/content/drive/MyDrive/新建文件夹/ERAI_Dataset_unsupervised.json')"
      ],
      "metadata": {
        "id": "Zd-hD40Wnfhq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('ERAI_Dataset_pairwise_train_with_translation.json')\n",
        "df2 = pd.read_json('ERAI_Dataset_pairwise_test_with_translation.json')\n",
        "df.reset_index(drop = True,inplace = True)\n",
        "df = df.dropna(axis = 0)\n",
        "\n",
        "\n",
        "\n",
        "df['post1_en']=df['post1_en'].apply(lambda x:x.replace('\\n',''))\n",
        "df['post2_en']=df['post2_en'].apply(lambda x:x.replace('\\n',''))\n"
      ],
      "metadata": {
        "id": "kMP47MjBohHg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_MODEL_NAME = 'yiyanghkust/finbert-tone'\n",
        "# 获取预测模型所使用的tokenizer\n",
        "\n",
        "#\"nlpaueb/sec-bert-shape\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "NANm77iwqEBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "80758b9fc34049b48fd18db77547bc84",
            "c14fd025b480431e95a664ed637f4e6c",
            "36b751824f03484eba845d96986c56c3",
            "8e541161d6a7465f85b61e8891d8a76e",
            "c6576dcfa7c740dfa3f76df817013066",
            "c9409d4400e94afc954e804f2689ed53",
            "0a6d6a3400c943b6a5b6517fcdf0c95d",
            "84daeef2f75443468a51a8ced03cb2aa",
            "a6459a60cb464144b892f2da3dc9db7a",
            "0095bbe22b3b4596b6f95f5d7093713b",
            "c5a1236040d34bd7ac52008e48ce9a9f",
            "45910cee5c1648c296fa85b1095b648e",
            "e60b45b350b84c76bb69cb8e0cece158",
            "a2bc9cf757314111b8944bca58d991e0",
            "70b1cb151dd14605b73d4fc225eb9f29",
            "b4c743c3d0f74647b0c983f90db51e35",
            "79bc7f8f012f4d9d896b7d5e6544ec8e",
            "e5f5dccc22a144c3965b91a710a44209",
            "28e3a5ddc78a4d33beba7d3fe8975ca1",
            "ab19bd588234400eb658c8026324c086",
            "cde9d128d1934bbf8c087a6938b14fa1",
            "7364c3e2475843ca88a3122ca48d0c07"
          ]
        },
        "outputId": "cd547397-ea46-4ca4-857d-3cead78e30ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80758b9fc34049b48fd18db77547bc84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/221k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45910cee5c1648c296fa85b1095b648e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_input_data(post1,post2,mpp_label,ml_label,max_len,mpp_value1,ml_value1,mpp_value2,ml_value2):\n",
        "  \n",
        "  \n",
        "  first_all_value = pd.concat([mpp_value1,ml_value1],axis=1)\n",
        "  second_all_value = pd.concat([mpp_value2,ml_value2],axis=1)\n",
        "  full_text = []\n",
        "  attention_mask = []\n",
        "  token_type_ids = []\n",
        "  first_length = []\n",
        "  second_length = []\n",
        "  for i,j in zip(post1,post2):\n",
        "    if len(i)>max_len:\n",
        "      i = i[:max_len]\n",
        "    if len(j)>max_len:\n",
        "      j = j[:max_len]\n",
        "    \n",
        "    i = tokenizer.tokenize(i)\n",
        "    j = tokenizer.tokenize(j)\n",
        "\n",
        "    first_length.append(len(i))\n",
        "    second_length.append(len(j))\n",
        "    \n",
        "    text = ['[CLS]']+i+['[SEP]']+j+['[SEP]']\n",
        "    full_text.append(tokenizer.convert_tokens_to_ids(text))\n",
        "    attention_mask.append(np.ones_like(text))\n",
        "\n",
        "    token_type_id = [0]*(len(i)+2) + [1]*(len(j)+1)\n",
        "    token_type_ids.append(token_type_id)\n",
        "\n",
        "  all_pad_tokens = pad_sequences(full_text, maxlen=max_len*2, padding='post', truncating='post')\n",
        "  all_mask = pad_sequences(attention_mask, maxlen=max_len*2, padding='post', truncating='post')\n",
        "  token_type_ids = pad_sequences(token_type_ids, maxlen=max_len*2, padding='post', truncating='post')\n",
        "  \n",
        "  return {\n",
        "      'input_ids': torch.tensor(all_pad_tokens,dtype=torch.long),\n",
        "      'attention_mask': torch.tensor(all_mask, dtype=torch.long),\n",
        "      'token_type_ids':torch.tensor(token_type_ids,dtype = torch.long),\n",
        "      'mpp_label':torch.tensor(mpp_label.values,dtype = torch.long),\n",
        "      'ml_label':torch.tensor(ml_label.values,dtype = torch.long),\n",
        "      'first_all_value': torch.tensor(first_all_value.values, dtype=torch.float),\n",
        "      'second_all_value': torch.tensor(second_all_value.values, dtype=torch.float),\n",
        "      'first_sen_len':torch.tensor(first_length,dtype = torch.long),\n",
        "      'second_sen_len':torch.tensor(second_length,dtype = torch.long)\n",
        "      \n",
        "  }\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "sS4W-xYLuQIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertNerClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes_cls,n_classes_reg):\n",
        "    super(BertNerClassifier, self).__init__()\n",
        "    self.bert = AutoModel.from_pretrained('yiyanghkust/finbert-tone')\n",
        "    self.drop = nn.Dropout(p=0.1)\n",
        "    self.out_cls = nn.Linear(self.bert.config.hidden_size, n_classes_cls)\n",
        "\n",
        "    self.out_reg = nn.Linear(self.bert.config.hidden_size, n_classes_reg)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask,token_type_ids,max_len,length1,length2):\n",
        "    output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask,\n",
        "      token_type_ids = token_type_ids\n",
        "\n",
        "    )\n",
        "    \n",
        "    output = self.drop(output[0])\n",
        "    \n",
        "    cls_info = output[0][0]\n",
        "    sent1_info = torch.mean(output[0][1:(length1+1)],dim=0)\n",
        "    sent2_info = torch.mean(output[0][length1+2:(length1+2+length2)],dim=0)\n",
        "    \n",
        "    # output = torch.cat((cls_info,sent1_info,sent2_info),dim = 0)\n",
        "    cls_info = self.out_cls(cls_info)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return self.sigmoid(cls_info),self.out_reg(sent1_info),self.out_reg(sent2_info)"
      ],
      "metadata": {
        "id": "r9ibb_OfB9Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgHH5evOn4jq"
      },
      "outputs": [],
      "source": [
        " \n",
        "class DataSequence(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "\n",
        "      self.features = data['input_ids']\n",
        "      self.mask = data['attention_mask']\n",
        "      self.token_type_ids = data['token_type_ids']\n",
        "      self.mpp_label = data['mpp_label']\n",
        "      self.ml_label = data['ml_label']\n",
        "      self.first_all_value = data['first_all_value']\n",
        "      self.second_all_value = data['second_all_value']\n",
        "      self.first_sen_len = data['first_sen_len']   \n",
        "      self.second_sen_len = data['second_sen_len']   \n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.mpp_label)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        return self.features[index],self.mask[index],self.token_type_ids[index],self.mpp_label[index],self.ml_label[index],self.first_all_value[index],self.second_all_value[index],self.first_sen_len[index],self.second_sen_len[index]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataloader(post1,post2,mpp_label,ml_label,max_len,mpp_value1,ml_value1,mpp_value2,ml_value2,batch_size):\n",
        "  data = generate_input_data(post1,post2,mpp_label,ml_label,max_len,mpp_value1,ml_value1,mpp_value2,ml_value2)\n",
        "  data = DataSequence(data)\n",
        "  dataloader = DataLoader(data, num_workers=10, batch_size=batch_size)\n",
        "  \n",
        "  return dataloader\n"
      ],
      "metadata": {
        "id": "zmRG1_cFiXm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "# total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "# scheduler = get_linear_schedule_with_warmup(\n",
        "#   optimizer,\n",
        "#   num_warmup_steps=0,\n",
        "#   num_training_steps=total_steps\n",
        "# )\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss_reg = nn.MSELoss().to(device)\n",
        "loss_cls = nn.BCELoss().to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3m3OxjI4qZYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgRZK6aQoZ_9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_and_eval(model, \n",
        "  train_loader, \n",
        "  validation_loader, \n",
        "  optimizer,  \n",
        "  device,\n",
        "  epoch,\n",
        "  # label_num \n",
        "  ):\n",
        "  model.train()\n",
        "  max_len = 256\n",
        "  mpp_accuracy_state = 0\n",
        "  ml_accuracy_state = 0\n",
        "  for epo in range(epoch):\n",
        "    \n",
        "    train_loss = []\n",
        "    \n",
        "    global train_mpp_predictions \n",
        "    train_mpp_predictions = []\n",
        "    global train_ml_predictions\n",
        "    train_ml_predictions = []\n",
        "    \n",
        "\n",
        "    validation_loss = []\n",
        "    \n",
        "    validation_mpp_predictions = []\n",
        "    validation_ml_predictions = []\n",
        "\n",
        "\n",
        "    global real_train_mpp \n",
        "    real_train_mpp = []\n",
        "    global real_train_ml\n",
        "    real_train_ml = []\n",
        "    real_validation_mpp = []\n",
        "    real_validation_ml = []\n",
        "    \n",
        "   \n",
        "    \n",
        "    for data in train_loader:\n",
        "      \n",
        "      input_ids = data[0].to(device)\n",
        "      attention_mask = data[1].to(device)\n",
        "      token_type_ids = data[2].to(device)\n",
        "      \n",
        "      mpp_targets = data[3].to(device)\n",
        "      ml_targets = data[4].to(device)\n",
        "      first_targets = data[5].to(device)\n",
        "      second_targets = data[6].to(device)\n",
        "      first_sen_len = data[7].to(device)\n",
        "      second_sen_len = data[8].to(device)\n",
        "      \n",
        "      \n",
        "\n",
        "      output_cls,output_sen1,ouptut_sen2 = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids = token_type_ids,\n",
        "        max_len = max_len,\n",
        "        length1 = first_sen_len,\n",
        "        length2 = second_sen_len\n",
        "   \n",
        "      )\n",
        "      \n",
        "      \n",
        "      \n",
        "      loss1 = loss_cls(output_cls.view(-1),torch.tensor([mpp_targets,ml_targets],dtype = torch.float).to(device))\n",
        "      \n",
        "      loss2 = loss_reg(output_sen1,first_targets.view(-1))\n",
        "      \n",
        "      loss3 = loss_reg(ouptut_sen2,second_targets.view(-1))\n",
        "      \n",
        "      loss = loss1+loss2+loss3\n",
        " \n",
        "      \n",
        "      \n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "      \n",
        "      \n",
        "      \n",
        "      if output_cls[0]>0.5:\n",
        "        train_mpp_predictions.append(1)\n",
        "      else:\n",
        "        train_mpp_predictions.append(0)\n",
        "      if output_cls[1]>0.5:\n",
        "        train_ml_predictions.append(1)\n",
        "      else:\n",
        "        train_ml_predictions.append(0)\n",
        "\n",
        "      real_train_mpp.append(mpp_targets.cpu().item())\n",
        "      real_train_ml.append(ml_targets.cpu().item())\n",
        "    \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for data in validation_loader:\n",
        "    \n",
        "        input_ids = data[0].to(device)\n",
        "        attention_mask = data[1].to(device)\n",
        "        token_type_ids = data[2].to(device)\n",
        "      \n",
        "        mpp_targets = data[3].to(device)\n",
        "        ml_targets = data[4].to(device)\n",
        "        first_targets = data[5].to(device)\n",
        "        second_targets = data[6].to(device)\n",
        "        first_sen_len = data[7].to(device)\n",
        "        second_sen_len = data[8].to(device)\n",
        "      \n",
        "\n",
        "        output_cls,output_sen1,ouptut_sen2 = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids = token_type_ids,\n",
        "        max_len = max_len,\n",
        "        length1 = first_sen_len,\n",
        "        length2 = second_sen_len\n",
        "   \n",
        "        )\n",
        "        loss1 = loss_cls(output_cls,torch.tensor([mpp_targets,ml_targets],dtype = torch.float).to(device))\n",
        "        \n",
        "        # loss2 = loss_reg(output_sen1,first_targets.view(-1))\n",
        "        \n",
        "        # loss3 = loss_reg(ouptut_sen2,second_targets.view(-1))\n",
        "        \n",
        "        loss = loss1\n",
        " \n",
        "      \n",
        "      \n",
        "\n",
        "        validation_loss.append(loss.item())\n",
        "      \n",
        "        if output_cls[0]>0.5:\n",
        "          validation_mpp_predictions.append(1)\n",
        "        else:\n",
        "          validation_mpp_predictions.append(0)\n",
        "        if output_cls[1]>0.5:\n",
        "          validation_ml_predictions.append(1)\n",
        "        else:\n",
        "          validation_ml_predictions.append(0)\n",
        "       \n",
        "\n",
        "        real_validation_mpp.append(mpp_targets.cpu().item())\n",
        "        real_validation_ml.append(ml_targets.cpu().item())\n",
        "    \n",
        "    train_mpp_accuracy = accuracy_score(real_train_mpp, train_mpp_predictions)\n",
        "    train_ml_accuracy = accuracy_score(real_train_ml, train_ml_predictions)\n",
        "    validation_mpp_accuracy = accuracy_score(real_validation_mpp, validation_mpp_predictions)\n",
        "    validation_ml_accuracy = accuracy_score(real_validation_ml, validation_ml_predictions)\n",
        "    \n",
        "    final_train_loss = np.mean(train_loss)\n",
        " \n",
        "    final_validation_loss = np.mean(validation_loss)\n",
        "\n",
        "\n",
        "    print(\n",
        "'Epoch [{}] Train Totol Loss: {:.4f}, Train MPP Accuracy: {:.4f}, Train ML Accuracy: {:.4f}, Valid Total Loss: {:.4f}, Valid MPP Accuracy: {:.4f}, Valid ML Accuracy: {:.4f}'\n",
        "    .format(epo+1,final_train_loss, train_mpp_accuracy, train_ml_accuracy,final_validation_loss,validation_mpp_accuracy,validation_ml_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed = [171,354,550,667,985]\n",
        "for i in random_seed:\n",
        "  \n",
        "  df = shuffle(df,random_state=i)\n",
        "\n",
        "  \n",
        "  train = df[0:156]\n",
        "\n",
        "  test = df[156:200]\n",
        "\n",
        "  train_post1 = train['post1_en']\n",
        "  train_post2 = train['post2_en']\n",
        "  train_mpp_label = train['MPP_label']\n",
        "  train_ml_label = train['ML_label']\n",
        "  train_mpp_value1 = train['MPP1'] \n",
        "  train_mpp_value2 = train['MPP2']\n",
        "  train_ml_value1 = train['ML1']\n",
        "  train_ml_value2 = train['ML2']\n",
        "\n",
        "  test_post1 = test['post1_en']\n",
        "  test_post2 = test['post2_en']\n",
        "  test_mpp_label = test['MPP_label']\n",
        "  test_ml_label = test['ML_label']\n",
        "  test_mpp_value1 = test['MPP1'] \n",
        "  test_mpp_value2 = test['MPP2']\n",
        "  test_ml_value1 = test['ML1']\n",
        "  test_ml_value2 = test['ML2']\n",
        "\n",
        "  max_len = 256\n",
        "  batch_size = 1\n",
        "  train_dataloader = generate_dataloader(train_post1,train_post2,train_mpp_label,train_ml_label,max_len,train_mpp_value1,train_ml_value1,train_mpp_value2,train_ml_value2,batch_size)\n",
        "  test_dataloader = generate_dataloader(test_post1,test_post2,test_mpp_label,test_ml_label,max_len,test_mpp_value1,test_ml_value1,test_mpp_value2,test_ml_value2,batch_size)\n",
        "\n",
        "  label_num_cls = 2\n",
        "  label_num_reg = 2\n",
        "  model= BertNerClassifier(label_num_cls,label_num_reg).to(device)\n",
        "  optimizer = AdamW(model.parameters(), lr=2e-6, correct_bias=False)\n",
        "  \n",
        "  \n",
        "  train_and_eval(model, \n",
        "    train_dataloader, \n",
        "    test_dataloader, \n",
        "    optimizer,  \n",
        "    device,\n",
        "    EPOCHS,\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "97anhQ4BEQ7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_prediction(model, \n",
        "  test_dataloader,  \n",
        "  optimizer,\n",
        "  device\n",
        "  ):\n",
        "  \n",
        "  test_mpp_predictions = []\n",
        "  test_ml_predictions = []\n",
        "  real_test_mpp = []\n",
        "  real_test_ml= []\n",
        "\n",
        "  \n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "    \n",
        "        input_ids = data[0].to(device)\n",
        "        attention_mask = data[1].to(device)\n",
        "        token_type_ids = data[2].to(device)\n",
        "      \n",
        "        mpp_targets = data[3].to(device)\n",
        "        ml_targets = data[4].to(device)\n",
        "        first_targets = data[5].to(device)\n",
        "        second_targets = data[6].to(device)\n",
        "        first_sen_len = data[7].to(device)\n",
        "        second_sen_len = data[8].to(device)\n",
        "      \n",
        "\n",
        "        output_cls,output_sen1,ouptut_sen2 = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids = token_type_ids,\n",
        "        max_len = max_len,\n",
        "        length1 = first_sen_len,\n",
        "        length2 = second_sen_len\n",
        "   \n",
        "        )\n",
        "     \n",
        "        \n",
        "      \n",
        "        if output_cls[0]>0.5:\n",
        "          test_mpp_predictions.append(1)\n",
        "        else:\n",
        "          test_mpp_predictions.append(0)\n",
        "        if output_cls[1]>0.5:\n",
        "          test_ml_predictions.append(1)\n",
        "        else:\n",
        "          test_ml_predictions.append(0)\n",
        "        # validation_ml_predictions += torch.sum(preds == ml_targets)\n",
        "\n",
        "        real_test_mpp.append(mpp_targets.cpu().item())\n",
        "        real_test_ml.append(ml_targets.cpu().item())\n",
        "\n",
        "        test_mpp_accuracy = accuracy_score(real_test_mpp, test_mpp_predictions)\n",
        "        test_ml_accuracy = accuracy_score(real_test_ml, test_ml_predictions)\n",
        "\n",
        "  \n",
        "\n",
        "  print('Test MMP ACCURACY_SCORE: {:.4f},Test ML ACCURACY_SCORE: {:.4f}'.format(test_mpp_accuracy,test_ml_accuracy))"
      ],
      "metadata": {
        "id": "hrlzlp9eIKW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('fincom_ml_bert_state.bin', map_location=torch.device(\"cuda:0\")))"
      ],
      "metadata": {
        "id": "T-okvJ0O_K4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883e5dbf-03ec-4cb4-bd21-960df0f0b785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_data(post1,post2,max_len):\n",
        " \n",
        "  full_text = []\n",
        "  attention_mask = []\n",
        "  token_type_ids = []\n",
        "  first_length = []\n",
        "  second_length = []\n",
        "  for i,j in zip(post1,post2):\n",
        "    if len(i)>max_len:\n",
        "      i = i[:max_len]\n",
        "    if len(j)>max_len:\n",
        "      j = j[:max_len]\n",
        "    \n",
        "    i = tokenizer.tokenize(i)\n",
        "    j = tokenizer.tokenize(j)\n",
        "\n",
        "    first_length.append(len(i))\n",
        "    second_length.append(len(j))\n",
        "    \n",
        "    text = ['[CLS]']+i+['[SEP]']+j+['[SEP]']\n",
        "    full_text.append(tokenizer.convert_tokens_to_ids(text))\n",
        "    attention_mask.append(np.ones_like(text))\n",
        "\n",
        "    token_type_id = [0]*(len(i)+2) + [1]*(len(j)+1)\n",
        "    token_type_ids.append(token_type_id)\n",
        "\n",
        "  all_pad_tokens = pad_sequences(full_text, maxlen=max_len*2, padding='post', truncating='post')\n",
        "  all_mask = pad_sequences(attention_mask, maxlen=max_len*2, padding='post', truncating='post')\n",
        "  token_type_ids = pad_sequences(token_type_ids, maxlen=max_len*2, padding='post', truncating='post')\n",
        "  \n",
        "  return {\n",
        "      'input_ids': torch.tensor(all_pad_tokens,dtype=torch.long),\n",
        "      'attention_mask': torch.tensor(all_mask, dtype=torch.long),\n",
        "      'token_type_ids':torch.tensor(token_type_ids,dtype = torch.long),\n",
        "      'first_sen_len':torch.tensor(first_length,dtype = torch.long),\n",
        "      'second_sen_len':torch.tensor(second_length,dtype = torch.long)\n",
        "      \n",
        "  }"
      ],
      "metadata": {
        "id": "8llDIyhTZwJp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FqzEQpsw5IJs"
      },
      "outputs": [],
      "source": [
        " \n",
        "class testSequence(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "\n",
        "      self.features = data['input_ids']\n",
        "      self.mask = data['attention_mask']\n",
        "      self.token_type_ids = data['token_type_ids']\n",
        "      self.first_sen_len = data['first_sen_len']   \n",
        "      self.second_sen_len = data['second_sen_len']   \n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.mpp_label)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        return self.features[index],self.mask[index],self.token_type_ids[index],self.first_sen_len[index],self.second_sen_len[index]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_dataloader(post1,post2,max_len,batch_size):\n",
        "  data = generate_test_data(post1,post2,max_len)\n",
        "  data = testSequence(data)\n",
        "  dataloader = DataLoader(data, num_workers=10, batch_size=batch_size)\n",
        "  \n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "q1gp6mDD6Dwc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_post1 = df2['post1_en']\n",
        "test_post2 = df2['post2_en']\n"
      ],
      "metadata": {
        "id": "ldxJziYA6dhq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = generate_test_dataloader(test_post1,test_post2,256,1)"
      ],
      "metadata": {
        "id": "DJFzDYEF81j7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujstkIDp9jIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def real_prediction(model, \n",
        "  test_dataloader,  \n",
        "  optimizer,\n",
        "  device\n",
        "  ):\n",
        "  \n",
        "  test_mpp_predictions = []\n",
        "  test_ml_predictions = []\n",
        "  real_test_mpp = []\n",
        "  real_test_ml= []\n",
        "\n",
        "  \n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "    \n",
        "        input_ids = data[0].to(device)\n",
        "        attention_mask = data[1].to(device)\n",
        "        token_type_ids = data[2].to(device)\n",
        "      \n",
        "        \n",
        "        first_sen_len = data[3].to(device)\n",
        "        second_sen_len = data[4].to(device)\n",
        "      \n",
        "\n",
        "        output_cls,output_sen1,ouptut_sen2 = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids = token_type_ids,\n",
        "        max_len = max_len,\n",
        "        length1 = first_sen_len,\n",
        "        length2 = second_sen_len\n",
        "   \n",
        "        )\n",
        "     \n",
        "        \n",
        "      \n",
        "        if output_cls[0]>0.5:\n",
        "          test_mpp_predictions.append(1)\n",
        "        else:\n",
        "          test_mpp_predictions.append(0)\n",
        "        if output_cls[1]>0.5:\n",
        "          test_ml_predictions.append(1)\n",
        "        else:\n",
        "          test_ml_predictions.append(0)\n",
        "        # validation_ml_predictions += torch.sum(preds == ml_targets)\n",
        "  return test_mpp_predictions,test_ml_predictions\n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "oOCSNsR--Bga"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mpp_predictions,test_ml_predictions = real_prediction(test_loader,optimizer,device)"
      ],
      "metadata": {
        "id": "ERJbpsfp-Zi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['MPP_prediction'] = test_mpp_predictions\n",
        "df2['ML_prediction'] = test_ml_predictions\n",
        "df2.to_json('ERAI_pairwise_[aiml]_[1].json')"
      ],
      "metadata": {
        "id": "hc3tEwcK_BRY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80758b9fc34049b48fd18db77547bc84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c14fd025b480431e95a664ed637f4e6c",
              "IPY_MODEL_36b751824f03484eba845d96986c56c3",
              "IPY_MODEL_8e541161d6a7465f85b61e8891d8a76e"
            ],
            "layout": "IPY_MODEL_c6576dcfa7c740dfa3f76df817013066"
          }
        },
        "c14fd025b480431e95a664ed637f4e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9409d4400e94afc954e804f2689ed53",
            "placeholder": "​",
            "style": "IPY_MODEL_0a6d6a3400c943b6a5b6517fcdf0c95d",
            "value": "Downloading config.json: 100%"
          }
        },
        "36b751824f03484eba845d96986c56c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84daeef2f75443468a51a8ced03cb2aa",
            "max": 533,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6459a60cb464144b892f2da3dc9db7a",
            "value": 533
          }
        },
        "8e541161d6a7465f85b61e8891d8a76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0095bbe22b3b4596b6f95f5d7093713b",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a1236040d34bd7ac52008e48ce9a9f",
            "value": " 533/533 [00:00&lt;00:00, 14.5kB/s]"
          }
        },
        "c6576dcfa7c740dfa3f76df817013066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9409d4400e94afc954e804f2689ed53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a6d6a3400c943b6a5b6517fcdf0c95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84daeef2f75443468a51a8ced03cb2aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6459a60cb464144b892f2da3dc9db7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0095bbe22b3b4596b6f95f5d7093713b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a1236040d34bd7ac52008e48ce9a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45910cee5c1648c296fa85b1095b648e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e60b45b350b84c76bb69cb8e0cece158",
              "IPY_MODEL_a2bc9cf757314111b8944bca58d991e0",
              "IPY_MODEL_70b1cb151dd14605b73d4fc225eb9f29"
            ],
            "layout": "IPY_MODEL_b4c743c3d0f74647b0c983f90db51e35"
          }
        },
        "e60b45b350b84c76bb69cb8e0cece158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79bc7f8f012f4d9d896b7d5e6544ec8e",
            "placeholder": "​",
            "style": "IPY_MODEL_e5f5dccc22a144c3965b91a710a44209",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "a2bc9cf757314111b8944bca58d991e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e3a5ddc78a4d33beba7d3fe8975ca1",
            "max": 226122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab19bd588234400eb658c8026324c086",
            "value": 226122
          }
        },
        "70b1cb151dd14605b73d4fc225eb9f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde9d128d1934bbf8c087a6938b14fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_7364c3e2475843ca88a3122ca48d0c07",
            "value": " 221k/221k [00:00&lt;00:00, 945kB/s]"
          }
        },
        "b4c743c3d0f74647b0c983f90db51e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79bc7f8f012f4d9d896b7d5e6544ec8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f5dccc22a144c3965b91a710a44209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28e3a5ddc78a4d33beba7d3fe8975ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab19bd588234400eb658c8026324c086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cde9d128d1934bbf8c087a6938b14fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7364c3e2475843ca88a3122ca48d0c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}